---
title: "Chapter 7: Monte Carlo Methods in Inference"
output:
  pagedown::html_paged:
    # change to true for a self-contained document, but it'll be a litte slower for Pandoc to render
    css: ["../style/my-style-page.css", "default-fonts", "default-page", "default"]
    self_contained: true
    number_sections: true
---

Monte Carlo methods may refer to any method in statistical inference or numerical analysis were simulation is used.

<br/>

We have so far learned about Monte Carlo methods for estimation.

<br/><br/><br/><br/><br/>

We will now look at Monte Carlo methods to estimate coverage probability for confidence intervals, Type I error of a test procedure, and power of a test.


In statistical inference there is uncertainty in an estimate. We will use repeated sampling (Monte Carlo methods) from a given probability model to investigate this uncertainty.

[ ]{.pagebreak}

# Monte Carlo Estimate of Coverage {data-short-title="Coverage"}

## Confidence Intervals

Recall from your intro stats class that a $95\%$ confidence interval for $\mu$ (when $\sigma$ is known and $X_1, \dots, X_n \stackrel{iid}{\sim} N(\mu, \sigma^2)$) is of the form

<br/><br/><br/>

Interpretation:

<br/><br/><br/><br/><br/>

Comments:

1. <br/><br/>

2. <br/><br/>

Mathematical interpretation:

[ ]{.pagebreak}

```{definition}
For $X_1, \dots, X_n \stackrel{iid}{\sim} N(\mu, \sigma^2)$, $\sigma$ known, the $(1 - \alpha)100\%$ *confidence interval for* $\mu$ is
$$
  \left(\overline{x} - z_{1 - \frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, \overline{x} + z_{1 - \frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right),
$$
where 
$$
  z_{1 - \frac{\alpha}{2}}  = 1 - \frac{\alpha}{2} \text{ quantile of } N(0, 1).
$$  
```

In general,

<br/><br/><br/><br/><br/><br/>

So, if we have formulas for $L$ and $U$, we can use Monte Carlo integration to estimate $\alpha$.

An estimate of $1 - \alpha$ tells us about the behavior of our estimator $[L, U]$ in practice.

## Vocabulary

We say $P(L < \theta < U) = P(\text{CI contains } \theta) = 1 - \alpha.$

<br/>

$1 - \alpha =$

<br/><br/>

$1 - \hat{\alpha} =$

[ ]{.pagebreak}


## Algorithm

Let $X \sim F_X$ and $\theta$ is the parameter of interest. 

```{example}

```
<br/><br/><br/>

Consider a confidence interval for $\theta$, $C = [L, U]$. 

Then, a Monte Carlo Estimator of Coverage could be obtained with the following algorithm.

[ ]{.pagebreak}

## Motivation

Why do we want empirical and nominal coverage to match?

<br/><br/><br/>

```{example}
Estimates of $[L, U]$ are biased.
```

<br/><br/><br/><br/><br/><br/><br/><br/>


```{example}
Estimates of $[L, U]$ have variance that is smaller than it should be.
```

<br/><br/><br/><br/><br/><br/><br/><br/>


```{example}
Estimates of $[L, U]$ have variance that is larger than it should be.
```



[ ]{.pagebreak}

[**Your Turn**]{.yourturn}

We want to examine empirical coverage for confidence intervals of the mean.

1. Coverage for CI for $\mu$ when $\sigma$ is known, $\left(\overline{x} - z_{1 - \frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, \overline{x} + z_{1 - \frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right)$.
    
    a. Simulate $X_1, \dots, X_n \stackrel{iid}{\sim} N(0, 1)$. Compute the empirical coverage for a $95\%$ confidence interval for $n = 5$ using $m = 1000$ MC samples.
    
    b.  Plot 100 confidence intervals using `geom_segment()` and add a line indicating the true value for $\mu = 0$. Color your intervals by if they contain $\mu$ or not.
    
    c. Repeat the Monte Carlo estimate of coverage 100 times. Plot the distribution of the results. This is the Monte Carlo estimate of the distribution of the coverage.
    
2. Repeat part 1 but without $\sigma$ known. Now you will plug in an estimage for $\sigma$ (using `sd()`) when you estimate the CI using the same formula that assumes $\sigma$ known. What happens to the empirical coverage? What can we do to improve the coverage? Now increase $n$. What happens to coverage?

3. Repeat 2a. when the data are distributed $\text{Unif}[-1, 1]$ and variance unknown. What happens to the coverage? What can we do to improve coverage in this case and why?

[ ]{.pagebreak}

# Monte Carlo Methods for Hypothesis Tests {data-short-title="Hypothesis Tests"}

There are two aspects of hypothesis tests that we will investigate through the use of Monte Carlo methods: Type I error and Power.

```{example}
Assume we want to test the following hypotheses

\begin{align*}
H_0&: \mu = 5 \\
H_a&: \mu > 5
\end{align*}

with the test statistic

$$
T^* = \frac{\overline{x} - 5}{s/\sqrt{n}}. 
$$  
  
This leads to the following decision rule:
```

<br/><br/><br/>

What are we assuming about $X$?

<br/><br/>

## Types of Errors

Type I error:

<br/>

Type II error:

[ ]{.pagebreak}

Usually we set $\alpha = 0.05$ or $0.10$, and choose a sample size such that power = $1 - \beta \ge 0.80$.

For simple cases, we can find formulas for $\alpha$ and $\beta$.

<br/><br/>

## MC Estimator of $\alpha$

Assume $X_1, \dots, X_n \sim F(\theta_0)$ (i.e., assume $H_0$ is true).

Then, we have the following hypothesis test --

\begin{align*}
H_0&: \theta = \theta_0 \\
H_a&: \theta > \theta_0
\end{align*}

and the statistics $T^*$, which is a test statistic computed from data. Then we **reject $H_0$** if $T^* >$ the critical value from the distribution of the test statistic.

This leads to the following algorithm to estimate the Type I error of the test ($\alpha$)

[ ]{.pagebreak}

[**Your Turn**]{.yourturn}

```{example, name = "Pearson's moment coefficient of skewness"}
Let $X \sim F$ where $E(X) = \mu$ and $Var(X) = \sigma^2$. Let
$$
\sqrt{\beta_1} = E\left[\left(\frac{X - \mu}{\sigma}\right)^3\right].  
$$

Then for a 

- symmetric distribution, $\sqrt{\beta_1} = 0$,
- positively skewed distribution, $\sqrt{\beta_1} > 0$, and 
- negatively skewed distribution, $\sqrt{\beta_1} < 0$.
  
<br/>
  
The following is an estimator for skewness

$$
\sqrt{b_1} = \frac{\dfrac{1}{n}\sum\limits_{i = 1}^n (X_i - \overline{X})^3}{\left[\dfrac{1}{n}\sum\limits_{i = 1}^n (X_i - \overline{X})^2\right]^{3/2}}.  
$$  
  
It can be shown by Statistical theory that if $X_1, \dots, X_n \sim N(\mu, \sigma^2)$, then as $n \rightarrow \infty$, 
$$
 \sqrt{b_1} \stackrel{\cdot}{\sim} N\left(0, \frac{6}{n}\right).
$$  
  
Thus we can test the following hypothesis
\begin{align*}
H_0&: \sqrt{\beta_1} = 0 \\
H_a&: \sqrt{\beta_1} \not= 0
\end{align*}
by comparing $\frac{\sqrt{b_1}}{\sqrt{\frac{6}{n}}}$ to a critical value from a $N(0, 1)$ distribution.

In practice, convergence of $\sqrt{b_1}$ to a $N\left(0, \frac{6}{n}\right)$ is slow.

<br/>

We want to assess $P(\text{Type I error})$ for $\alpha = 0.05$ for $n = 10, 20, 30, 50, 100, 500$.
```

[ ]{.pagebreak}

```{r, message=FALSE, warning=FALSE, fig.height = 3}
library(tidyverse)

# compare a symmetric and skewed distribution
data.frame(x = seq(0, 1, length.out = 1000)) %>%
  mutate(skewed = dbeta(x, 6, 2),
         symmetric = dbeta(x, 5, 5)) %>%
  gather(type, dsn, -x) %>%
  ggplot() +
  geom_line(aes(x, dsn, colour = type, lty = type))
```
```{r, fig.show="hold", out.width="50%", message = FALSE, warning = FALSE}
## write a skewness function based on a sample x
skew <- function(x) {
  
}

## check skewness of some samples
n <- 100
a1 <- rbeta(n, 6, 2)
a2 <- rbeta(n, 2, 6)

## two symmetric samples
b1 <- rnorm(100)
b2 <- rnorm(100)

## fill in the skewness values
ggplot() + geom_histogram(aes(a1)) + xlab("Beta(6, 2)") + ggtitle(paste("Skewness = "))
ggplot() + geom_histogram(aes(a2)) + xlab("Beta(2, 6)") + ggtitle(paste("Skewness = "))
ggplot() + geom_histogram(aes(b1)) + xlab("N(0, 1)") + ggtitle(paste("Skewness = "))
ggplot() + geom_histogram(aes(b2)) + xlab("N(0, 1)") + ggtitle(paste("Skewness = "))
```

```{r}
## Assess the P(Type I Error) for alpha = .05, n = 10, 20, 30, 50, 100, 500
```

```{example, name = "Pearson's moment coefficient of skewness with variance correction"}
One way to improve performance of this statistic is to adjust the variance for small samples. It can be shown that
$$
Var(\sqrt{b_1}) = \frac{6(n - 2)}{(n + 1)(n + 3)}.  
$$  
Assess the Type I error rate of a skewness test using the finite sample correction variance.
```








